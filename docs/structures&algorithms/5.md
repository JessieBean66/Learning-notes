### 如何实现随机访问？

数组（Array）是一种`线性表`数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

- **线性表（Linear List）**。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。

    相对立的概念是**非线性表**，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。


- **连续的内存空间和相同类型的数据**。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：`“随机访问”`。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。

*数组是如何实现根据下标随机访问数组元素的吗？*

我们拿一个长度为10的int类型的数组`int[] a = new int[10]`来举例。在我画的这个图中，计算机给数组`a[10]`，分配了一块连续内存空间`1000～1039`，其中，内存块的首地址为`base_address = 1000`。

计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：

    a[i]_address = base_address + i * data_type_size

其中`data_type_size`表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是int类型数据，所以data_type_size就为4个字节。

**常常会问数组和链表的区别：**

"链表适合插入、删除，时间复杂度O(1)； 数组支持随机访问，根据下标随机访问的时间复杂度为O(1)。"

注意：数组是适合查找操作，但是查找的时间复杂度并不为O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是`O(logn)`。所以，正确的表述应该是，数组支持`随机访问`，根据下标随机访问的时间复杂度为`O(1)`。


### 低效的“插入”和“删除”

- **插入操作**

假设数组的长度为n，现在，如果我们需要将一个数据插入到数组中的第k个位置。为了把第k个位置腾出来，给新来的数据，我们需要将第k～n这部分的元素都顺序地往后挪一位。那插入操作的时间复杂度是多少呢？

1. 如果在数组的`末尾插入元素`，那就不需要移动数据了，这时的时间复杂度为O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为(1+2+…n)/n=O(n)。

2. 如果数组中的数据是`有序`的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移k之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数组插入到第k个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第k位的数据搬移到数组元素的最后，把新的元素直接放入第k个位置。

    [a, b, c, d, e] 插入一个x在第三个位置,变成下面的数据
    [a, b, x, d, e, c]

按这种处理技巧，在特定场景下，在第k个位置插入一个元素的时间复杂度就会`降为O(1)`。这个处理思想在快排中也会用到，我会在排序那一节具体来讲，这里就说到这儿。


- **删除操作**

如果我们要删除第k个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。

和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为`O(1)`；如果删除开头的数据，则最坏情况时间复杂度为`O(n)`；平均情况时间复杂度也为`O(n)`。

来个特殊场景的例子：数组a[10]中存储了8个元素：【a，b，c，d，e，f，g，h】。现在，我们要依次删除a，b，c三个元素。

为了避免`d，e，f，g，h`这几个数据会被`搬移三次`，我们可以先`记录`下已经`删除的数据`。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

如果你了解JVM，你会发现，这不就是**JVM标记清除垃圾回收算法**的核心思想吗？没错，数据结构和算法的魅力就在于此，很`多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。`如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。

### 警惕数组的访问越界问题
但并非所有的语言都像C一样，把数组越界检查的工作丢给程序员来做，像Java本身就会做越界检查，比如下面这几行Java代码，就会抛出java.lang.ArrayIndexOutOfBoundsException。

    int[] a = new int[3];
    a[3] = 10;


### 容器能否完全替代数组？

针对数组类型，很多语言都提供了容器类，比如Java中的ArrayList、C++ STL中的vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？

`ArrayList`最大的优势就是**可以将很多数组操作的细节封装起来**,还**支持动态扩容**。

数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果使用ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为1.5倍大小。

如果事先能确定需要存储的数据大小，最好在创建ArrayList的时候事先指定数据大小。事先指定数据大小可以省掉很多次内存申请和数据搬移操作。

数组和ArrayList的使用场景:

1. Java ArrayList无法存储基本类型，比如int、long，需要封装为Integer、Long类，而Autoboxing、Unboxing则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。

2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到ArrayList提供的大部分方法，也可以直接使用数组。

3. 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如Object[][] array；而用容器的话则需要这样定义：`ArrayList<ArrayList > array`。

我总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。



###  所以为什么大多数编程语言中，数组要从0开始编号，而不是从1开始呢？

从数组存储的内存模型上来看，“`下标`”最确切的定义应该是“`偏移（offset）`” 。最主要的原因可能是历史原因。

